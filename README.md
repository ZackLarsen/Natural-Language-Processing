# Natural-Language-Processing

This was an advanced topics course in artificial intelligence, CSC 594. This course loosely followed the NLP text from Dan Jurafsky of Stanford's NLP group, with extra lecture material provided by the professor. Assignments involved writing language models, POS taggers, and the Viterbi decoding algorithm for Hidden Markov Models, all in base Python without being able to use NLTK or any other library for NLP tasks. 

Course covered NLP topics such as part-of-speech taggers, context-free grammars, dependency parsing, CKY dynamic programming, Hidden Markov Models, ngram language modeling, and other advanced NLP concepts.

Final project consisted of a research paper on the students' choices of advanced topics. I chose to research word2vec and GloVe word embedding models, as well as multiclass sentiment classification machine learning models.
